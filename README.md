# VPPâš¡

> [**VPP: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation**](https://arxiv.org/abs/2307.16605), **NeurIPS 2023** <br>
> [Zekun Qi](https://scholar.google.com/citations?user=ap8yc3oAAAAJ), [Muzhou Yu](https://github.com/muzhou-yu), [Runpei Dong](https://runpeidong.com/) and [Kaisheng Ma](http://group.iiis.tsinghua.edu.cn/~maks/leader.html) <br>

[arXiv](https://arxiv.org/abs/2307.16605)

## News

- ðŸŽ† Sep, 2023: [**VPP**](https://arxiv.org/abs/2307.16605) is accepted to NeurIPS 2023.
- ðŸ’¥ Aug, 2023: Check out our previous work [**ACT**](https://arxiv.org/abs/2212.08320) and [**ReCon**](https://arxiv.org/abs/2302.02318) about 3D represent learning, which have been accepted by ICLR & ICML 2023.

----


This repository contains the code release of VPPâš¡: Efficient Conditional 3D Generation via Voxel-Point Progressive Representation.

<div  align="center">    
 <img src="./figure/generation.png" width = "1100"  align=center />
</div>

Code will be coming soon.

## Contact

If you have any questions related to the code or the paper, feel free to email Zekun (`qizekun@gmail.com`). 

## License

VPP is released under MIT License. See the [LICENSE](./LICENSE) file for more details.

## Acknowledgements

This codebase is built upon [Point-MAE](https://github.com/Pang-Yatian/Point-MAE), [CLIP](https://github.com/openai/CLIP) and [SLIDE](https://github.com/SLIDE-3D/SLIDE)

## Citation

If you find our work useful in your research, please consider citing:

```latex
@inproceedings{vpp2023,
title={{VPP}: Efficient Universal 3D Generation via Voxel-Point Progressive Representation},
author={Qi, Zekun and Yu, Muzhou and Dong, Runpei and Ma, Kaisheng},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=etd0ebzGOG}
}
```
